{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67512316",
   "metadata": {},
   "source": [
    "## Distributed batch_inference with dask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38051a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c96b992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_166/2605898639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistilBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFDistilBertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscheduler_setup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloaded_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "pd.options.display.max_rows = 999\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import gcsfs\n",
    "import s3fs\n",
    "import pickle\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, optimizers, losses\n",
    "from scheduler_setup import loaded_models\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78a488",
   "metadata": {},
   "source": [
    "## start dask workers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fb20a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Hyperplane: selecting worker node pool\n",
      "ðŸ‘‰ Hyperplane: selecting scheduler node pool\n",
      "Creating scheduler pod on cluster. This may take some time.\n",
      "ðŸ‘‰ Hyperplane: spinning up a dask cluster with a scheduler as a standalone container.\n",
      "ðŸ‘‰ Hyperplane: In a few minutes you'll be able to access the dashboard at https://ds.hyperplane.dev/dask-cluster-c76da13e-b7fa-4d2f-a620-895721e9c986/status\n",
      "ðŸ‘‰ Hyperplane: to get logs from all workers, do `cluster.get_logs()`\n"
     ]
    }
   ],
   "source": [
    "from hyperplane import notebook_common as nc\n",
    "\n",
    "client, cluster = nc.initialize_cluster(\n",
    "    nprocs = 3,\n",
    "    nthreads = 5,\n",
    "    ram_gb_per_proc = 4,\n",
    "    cores_per_worker = 15,\n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1efbfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.14 ms, sys: 2.34 ms, total: 11.5 ms\n",
      "Wall time: 8.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tcp://10.1.113.16:35955': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:37409': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:41277': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:35745': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:41753': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:45565': {'status': 'OK'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from dask.distributed import PipInstall\n",
    "plugin = PipInstall(packages=[\"s3fs\"], pip_options=[\"--upgrade\"])\n",
    "client.register_worker_plugin(plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37730412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://10.1.113.16:35955': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:37409': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:41277': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:35745': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:41753': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:45565': {'status': 'OK'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upload_file('scheduler_setup.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce62a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lWC-xP3rd6obsecCYsGZRg</td>\n",
       "      <td>ak0TdVmGKo4pwqdJSTLwWw</td>\n",
       "      <td>buF9druCkbuXLX526sGELQ</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparently Prides Osteria had a rough summer a...</td>\n",
       "      <td>1412998442000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8bFej1QE5LXp4O05qjGqXA</td>\n",
       "      <td>YoVfDbnISlW0f7abNQACIg</td>\n",
       "      <td>RA4V8pr014UyUbDvI-LW2A</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This store is pretty good. Not as great as Wal...</td>\n",
       "      <td>1435955905000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  lWC-xP3rd6obsecCYsGZRg  ak0TdVmGKo4pwqdJSTLwWw  buF9druCkbuXLX526sGELQ   \n",
       "1  8bFej1QE5LXp4O05qjGqXA  YoVfDbnISlW0f7abNQACIg  RA4V8pr014UyUbDvI-LW2A   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      4       3      1     1   \n",
       "1      4       1      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  Apparently Prides Osteria had a rough summer a...  1412998442000000000  \n",
       "1  This store is pretty good. Not as great as Wal...  1435955905000000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_parquet(\n",
    "#     \"s3://d2v-tmp/demo/bach_inference/data/yelp_review_dask.parquet\"\n",
    "    \"gs://pipeline_data/ray_data/yelp_review_dask.parquet\"\n",
    ")\n",
    "print(df.npartitions)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf50a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apparently Prides Osteria had a rough summer as evidenced by the almost empty dining room at 6:30 on a Friday night. However new blood in the kitchen seems to have revitalized the food from other customers recent visits. Waitstaff was warm but unobtrusive. By 8 pm or so when we left the bar was full and the dining room was much more lively than it had been. Perhaps Beverly residents prefer a later seating. \\n\\nAfter reading the mixed reviews of late I was a little tentative over our choice but luckily there was nothing to worry about in the food department. We started with the fried dough, burrata and prosciutto which were all lovely. Then although they don't offer half portions of pasta we each ordered the entree size and split them. We chose the tagliatelle bolognese and a four cheese filled pasta in a creamy sauce with bacon, asparagus and grana frita. Both were very good. We split a secondi which was the special Berkshire pork secreto, which was described as a pork skirt steak with garlic potato purÃ©e and romanesco broccoli (incorrectly described as a romanesco sauce). Some tables received bread before the meal but for some reason we did not. \\n\\nManagement also seems capable for when the tenants in the apartment above began playing basketball she intervened and also comped the tables a dessert. We ordered the apple dumpling with gelato and it was also quite tasty. Portions are not huge which I particularly like because I prefer to order courses. If you are someone who orders just a meal you may leave hungry depending on you appetite. Dining room was mostly younger crowd while the bar was definitely the over 40 set. Would recommend that the naysayers return to see the improvement although I personally don't know the former glory to be able to compare. Easy access to downtown Salem without the crowds on this month of October.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head(2).text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e18f60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      object\n",
       "user_id        object\n",
       "business_id    object\n",
       "stars           int64\n",
       "useful          int64\n",
       "funny           int64\n",
       "cool            int64\n",
       "text           object\n",
       "date            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    df['text'] = df.text.replace(r'\\r+|\\n+|\\t+','', regex=True)\n",
    "    df['text'] = df.text.str.lower()\n",
    "    return df\n",
    "\n",
    "df = df.map_partitions(clean_text)\n",
    "df['text'] = df.text.astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc19dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bd375",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ff46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df: pd.DataFrame, batch_size : str) -> pd.DataFrame:\n",
    "    import sys\n",
    "#     sys.path.append('/root')\n",
    "    from scheduler_setup import loaded_models\n",
    "    model, model_name, max_len = loaded_models['model']\n",
    "    \n",
    "    tkzr = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    inputs = tkzr(df.text.tolist(),    \n",
    "                  padding='max_length',\n",
    "                  truncation=True, \n",
    "                  return_tensors='tf')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'],inputs['attention_mask']))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    import numpy as np\n",
    "    predictions = []\n",
    "    for i, (token_ids, masks) in enumerate(dataset):\n",
    "        pred = model(token_ids, attention_mask=masks)\n",
    "        labels = np.argmax(tf.nn.softmax(pred.logits, axis=0).numpy(), axis = 1)\n",
    "        predictions.append(labels)\n",
    "    predictions = np.hstack(predictions)\n",
    "    df['pred'] = predictions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7477f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 9)\n",
      "CPU times: user 9.07 s, sys: 1.82 s, total: 10.9 s\n",
      "Wall time: 2.69 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lWC-xP3rd6obsecCYsGZRg</td>\n",
       "      <td>ak0TdVmGKo4pwqdJSTLwWw</td>\n",
       "      <td>buF9druCkbuXLX526sGELQ</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>apparently prides osteria had a rough summer a...</td>\n",
       "      <td>1412998442000000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8bFej1QE5LXp4O05qjGqXA</td>\n",
       "      <td>YoVfDbnISlW0f7abNQACIg</td>\n",
       "      <td>RA4V8pr014UyUbDvI-LW2A</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>this store is pretty good. not as great as wal...</td>\n",
       "      <td>1435955905000000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDhkzczKjLshODbqDoNLSg</td>\n",
       "      <td>eC5evKn1TWDyHCyQAwguUw</td>\n",
       "      <td>_sS2LBIGNT5NQb6PD1Vtjw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i called wvm on the recommendation of a couple...</td>\n",
       "      <td>1369773486000000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T5fAqjjFooT4V0OeZyuk1w</td>\n",
       "      <td>SFQ1jcnGguO0LYWnbbftAA</td>\n",
       "      <td>0AzLzHfOJgL7ROwhdww2ew</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>i've stayed at many marriott and renaissance m...</td>\n",
       "      <td>1262917755000000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sjm_uUcQVxab_EeLCqsYLg</td>\n",
       "      <td>0kA0PAJ8QFMeveQWHFqz2A</td>\n",
       "      <td>8zehGz9jnxPqXtOc7KaJxA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the food is always great here. the service fro...</td>\n",
       "      <td>1311876301000000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  lWC-xP3rd6obsecCYsGZRg  ak0TdVmGKo4pwqdJSTLwWw  buF9druCkbuXLX526sGELQ   \n",
       "1  8bFej1QE5LXp4O05qjGqXA  YoVfDbnISlW0f7abNQACIg  RA4V8pr014UyUbDvI-LW2A   \n",
       "2  NDhkzczKjLshODbqDoNLSg  eC5evKn1TWDyHCyQAwguUw  _sS2LBIGNT5NQb6PD1Vtjw   \n",
       "3  T5fAqjjFooT4V0OeZyuk1w  SFQ1jcnGguO0LYWnbbftAA  0AzLzHfOJgL7ROwhdww2ew   \n",
       "4  sjm_uUcQVxab_EeLCqsYLg  0kA0PAJ8QFMeveQWHFqz2A  8zehGz9jnxPqXtOc7KaJxA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      4       3      1     1   \n",
       "1      4       1      0     0   \n",
       "2      5       0      0     0   \n",
       "3      2       1      1     1   \n",
       "4      4       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  apparently prides osteria had a rough summer a...  1412998442000000000   \n",
       "1  this store is pretty good. not as great as wal...  1435955905000000000   \n",
       "2  i called wvm on the recommendation of a couple...  1369773486000000000   \n",
       "3  i've stayed at many marriott and renaissance m...  1262917755000000000   \n",
       "4  the food is always great here. the service fro...  1311876301000000000   \n",
       "\n",
       "   pred  \n",
       "0     0  \n",
       "1     1  \n",
       "2     1  \n",
       "3     0  \n",
       "4     1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## test out with one small df \n",
    "df_local = df.head(5)\n",
    "print(df_local.shape)\n",
    "predict(df_local, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78aa70fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df_sample = df.sample(0.001)\n",
    "len(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58cf95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dtype\n",
    "meta = df.dtypes.to_dict()\n",
    "meta['pred'] = 'int'\n",
    "\n",
    "df_result = df_sample.map_partitions(predict, batch_size=8 , meta = meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01169561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 743 ms, sys: 19.1 ms, total: 762 ms\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_result_local = df_result.compute()\n",
    "df_result_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69b05a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040a413",
   "metadata": {},
   "source": [
    "#### with hyperplane dask distributed, inference on 1000 samples finished in 1min 42s\n",
    "In comparison, a non-paralized version which has an estimated time of 8 min 46s, it's a 5.1x speed up, coresponds to the dask cluster of 6 workers. Given more workers and GPU, the speed up will be even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb136b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
