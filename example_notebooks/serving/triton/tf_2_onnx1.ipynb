{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dadc4adc",
   "metadata": {},
   "source": [
    "## Convert tensorflow model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66db22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    " \n",
    "# !{sys.executable} -m pip install --quiet --upgrade tensorflow==2.3.0\n",
    "# !{sys.executable} -m pip install --quiet --upgrade onnxruntime==1.4.0\n",
    "# !{sys.executable} -m pip install --quiet --upgrade onnxruntime-tools==1.4.0\n",
    "# !{sys.executable} -m pip install --quiet --upgrade keras2onnx==1.7.0\n",
    "# !{sys.executable} -m pip install --quiet transformers==3.0.2\n",
    "# !{sys.executable} -m pip install --quiet onnxconverter_common\n",
    "# !{sys.executable} -m pip install --quiet wget pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fd74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx; print(tf2onnx.__version__)\n",
    "# import keras2onnx; print(keras2onnx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0a8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable_overwrite = False\n",
    "# total_runs = 100\n",
    "# max_sequence_length = 512\n",
    "\n",
    "# import os\n",
    "# cache_dir = './cache_models'\n",
    "# output_dir = './onnx_models'\n",
    "# for directory in [cache_dir, output_dir]:\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "        \n",
    "# import tensorflow as tf\n",
    "# tf.config.set_visible_devices([], 'GPU') # Disable GPU for fair comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562e92c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import (TFBertForQuestionAnswering, BertTokenizer)\n",
    "\n",
    "# #model_name_or_path = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "# model_name_or_path = \"bert-base-cased\"\n",
    "# is_fine_tuned = (model_name_or_path == 'bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "# # Load model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name_or_path, do_lower_case=True, cache_dir=cache_dir)\n",
    "# model = TFBertForQuestionAnswering.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
    "# # Needed this to export onnx model with multiple inputs with TF 2.2\n",
    "# model._saved_model_inputs_spec = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97adf88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "\n",
    "# question, text = \"What is Hyperplane?\", \"Hyperplane  is an end-to-end platform designed to take AI teams from ideation to production at breakthrough speeds. We built Hyperplane because we needed a powerful platform for our scientists to design, develop, deploy and maintain their own work in production.\"\n",
    "# # Pad to max length is needed. Otherwise, position embedding might be truncated by constant folding.\n",
    "# inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors='tf',\n",
    "#                                max_length=max_sequence_length, pad_to_max_length=True, truncation=True)\n",
    "# start_scores, end_scores = model(inputs)\n",
    "\n",
    "# num_tokens = len(inputs[\"input_ids\"][0])\n",
    "# if is_fine_tuned:\n",
    "#     all_tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "#     print(\"The answer is:\", ' '.join(all_tokens[numpy.argmax(start_scores) : numpy.argmax(end_scores)+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400ea778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Inference time for sequence length 512 = 881.58 ms\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# for _ in range(total_runs):\n",
    "#     start_scores, end_scores = model(inputs)\n",
    "# end = time.time()\n",
    "# print(\"Tensorflow Inference time for sequence length {} = {} ms\".format(num_tokens, format((end - start) * 1000 / total_runs, '.2f')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a71ed1",
   "metadata": {},
   "source": [
    "## convert to onnx through transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a49f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-512_A-8.zip\n",
    "# !unzip *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7a76814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Building PyTorch model from configuration: BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Converting TensorFlow checkpoint from /root/ds-29faf59/starter_notebooks/triton/torch_model/bert_model.ckpt\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/embeddings/position_embeddings with shape [512, 512]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 512]\n",
      "Loading TF weight bert/embeddings/word_embeddings with shape [30522, 512]\n",
      "2021-08-27 22:11:17.066930: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 62509056 exceeds 10% of free system memory.\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [2048]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [512, 2048]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [2048, 512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [2048]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [512, 2048]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [2048, 512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [2048]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [512, 2048]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [2048, 512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [512, 512]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [2048]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [512, 2048]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [512]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [2048, 512]\n",
      "Loading TF weight bert/pooler/dense/bias with shape [512]\n",
      "Loading TF weight bert/pooler/dense/kernel with shape [512, 512]\n",
      "Loading TF weight cls/predictions/output_bias with shape [30522]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [512]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [512]\n",
      "Loading TF weight cls/predictions/transform/dense/bias with shape [512]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel with shape [512, 512]\n",
      "Loading TF weight cls/seq_relationship/output_bias with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_weights with shape [2, 512]\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n",
      "Save PyTorch model to ./torch_model/pytorch_model.bin\n",
      "CPU times: user 144 ms, sys: 50.5 ms, total: 194 ms\n",
      "Wall time: 7.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# !export BERT_BASE_DIR=\"/root/ds-29faf59/starter_notebooks/trito/torch_model\"\n",
    "\n",
    "!transformers-cli convert --model_type bert \\\n",
    "  --tf_checkpoint ./torch_model/bert_model.ckpt \\\n",
    "  --config ./torch_model/bert_config.json \\\n",
    "  --pytorch_dump_output ./torch_model/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f94650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "matrixprofile 1.1.10 requires protobuf==3.11.2, but you have protobuf 3.17.3 which is incompatible.\n",
      "gql 3.0.0a6 requires graphql-core<3.2,>=3.1.5, but you have graphql-core 2.3.2 which is incompatible.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers --quiet\n",
    "!pip install -U tensorflow --quiet\n",
    "!pip install -U torch --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca78d256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 2.6.0\n",
      "torch 1.9.0+cu102\n",
      "transformers 4.9.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(f'tensorflow {tf.__version__}')\n",
    "print(f'torch {torch.__version__}')\n",
    "print(f'transformers {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf28154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import activations, optimizers, losses\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce65af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "     'Great customer service! The food was delicious! Definitely a come again.',\n",
    "     'The VEGAN options are super fire!!! And the plates come in big portions. Very pleased with this spot, I\\'ll definitely be ordering again',\n",
    "     'Come on, this place is family owned and operated, they are super friendly, the tacos are bomb.',\n",
    "     'This is such a great restaurant. Multiple times during days that we don\\'t want to cook, we\\'ve done takeout here and it\\'s been amazing. It\\'s fast and delicious.',\n",
    "     'Staff is really nice. Food is way better than average. Good cost benefit.',\n",
    "     'pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top.',\n",
    "     'At such a *fine* institution, I find the lack of knowledge and respect for the art appalling',\n",
    "     'If I could give one star I would...I walked out before my food arrived the customer service was horrible!',\n",
    "     'Wow the slowest drive thru I\\'ve ever been at WOWWWW. Horrible I won\\'t be coming back here ever again',\n",
    "     'Service: 1 out of 5 stars. They will mess up your order, not have it ready after 30 mins calling them before. Worst ran family business Ive ever seen.'\n",
    "]\n",
    "\n",
    "y = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03474a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review: 'Great customer service! The food was delicious! Definitely a come again.'\n",
      "input ids: [101, 2307, 8013, 2326, 999, 1996, 2833, 2001, 12090, 999, 5791, 1037, 2272, 2153, 1012, 102]\n",
      "attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/root/ds-29faf59/starter_notebooks/triton/torch_model\"\n",
    "\n",
    "MODEL_PATH = 'bert-base-uncased'\n",
    "MAX_LEN = 128\n",
    "\n",
    "review = x[0]\n",
    "tkzr = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "inputs = tkzr(review, max_length=MAX_LEN, truncation=True, padding=True)\n",
    "\n",
    "print(f'review: \\'{review}\\'')\n",
    "print(f'input ids: {inputs[\"input_ids\"]}')\n",
    "print(f'attention mask: {inputs[\"attention_mask\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0f173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs[\"attention_mask\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c424659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ffcf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1ab6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "# raw_datasets = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db9769c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc0c51777344dacbf2a97123989364b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f358fb9327384e95a3abebaf9f99a712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25adf5f4facd4d37b4d57658567308cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657dfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100))\n",
    "# small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e323636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab056c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# from transformers import Trainer\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8519ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d97ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b887b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Hugging Face ONNX Exporter tool [-h] -m MODEL\n",
      "                                       [--feature {causal-lm,causal-lm-with-past,default,default-with-past,seq2seq-lm,seq2seq-lm-with-past,sequence-classification,sequence-classification-with-past}]\n",
      "                                       [--opset OPSET] [--atol ATOL]\n",
      "                                       output\n",
      "\n",
      "positional arguments:\n",
      "  output                Path indicating where to store generated ONNX model.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -m MODEL, --model MODEL\n",
      "                        Model's name of path on disk to load.\n",
      "  --feature {causal-lm,causal-lm-with-past,default,default-with-past,seq2seq-lm,seq2seq-lm-with-past,sequence-classification,sequence-classification-with-past}\n",
      "                        Export the model with some additional feature.\n",
      "  --opset OPSET         ONNX opset version to export the model with (default\n",
      "                        12).\n",
      "  --atol ATOL           Absolute difference tolerence when validating the\n",
      "                        model.\n"
     ]
    }
   ],
   "source": [
    "!python -m transformers.onnx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6813809",
   "metadata": {},
   "source": [
    "### may need to add  model_type key in the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc42520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using framework PyTorch: 1.9.0+cu102\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2158: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert all(\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model outputs' name match reference model ({'pooler_output', 'last_hidden_state'}\n",
      "\t- Validating ONNX Model output \"last_hidden_state\":\n",
      "\t\t-[✓] (2, 8, 256) matches (2, 8, 256)\n",
      "\t\t-[✓] all values close (atol: 0.0001)\n",
      "\t- Validating ONNX Model output \"pooler_output\":\n",
      "\t\t-[✓] (2, 256) matches (2, 256)\n",
      "\t\t-[✓] all values close (atol: 0.0001)\n",
      "All good, model saved at: onnx/bert-base-cased/model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m transformers.onnx --model=\"./torch_model\" onnx/bert-base-cased/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663e62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
